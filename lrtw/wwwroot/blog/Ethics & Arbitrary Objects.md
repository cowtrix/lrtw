2021-02-25 #writing #philosophy

There are many abstract, mental systems that we build throughout our lives. We build systems firstly in order to interpret our memories and sensory input into an internal simulation of "reality", our experience up to that moment. Secondly, we then run simulations of the future and predict their probability. These systems are abstract objects that exist within your mind that define your experience within the world.

However, at some point, your systems will come to the final part of this process of existence: selecting which predicted future you should pursue. Eventually you have to answer questions like "Why should we reduce human suffering?" This will involve using some form of heuristic to determine future value, and then balancing that value against probability. 

But what is this heuristic exactly? Consider the plethora of future states that lay before you, running the full gamut from your worst fears to your wildest dreams. If, right now, you could choose which future to inhabit with perfect information about the outcomes of each branch of the timeline, which mental system would you choose to evaluate this choice? What would you call it?

I've thought about this a lot these last few months, and about that question. I propose that:

> A system of ethics is any system which predicts future states of the universe and values them.

I think that's an interesting definition to explore. It avoids anthropocentrism, is an objective description of the subjective, and captures the essential quality of that system. But a second statement has also haunted me:

> All ethical heuristics are arbitrary.

What exactly do I mean when I say arbitrary? Specifically here I mean that there is no correlation between the evaluation function of future timelines and their probability. Put another way, the evaluation function does not exist or emerge from any physical laws of the universe.

As far as I can tell, the universe contains no preference between future states that you find undesirable and states you find desirable. The laws of physics contains no preference between an Earth that remains habitable and one that is smacked with a world-killer asteroid in a century. My personal preference between those future states is arbitrary - and, critically, because that valuation is arbitrary it is by definition an ethical one.

I cannot stress enough that when I describe these preferences between future states as arbitrary, I do not mean that they are unimportant. In fact, I mean exactly the opposite. These arbitrary structures determine the shape of our existence and our world. All that can be inferred, measured, and determined by reason is solid and non-arbitrary. But reason does not rank future states - only an arbitrary mechanism can do that. Empirical measures may enter into the determination of action, but they cannot ultimately value them. 

I'm reminded a little of the concept of universal constants - of suggestions of modern physics that suggests that our universe has a number of arbitrary variables such as the strength of the weak force, the speed of light, the mass of the electron. It seems as if the laws of our universe could apply with any permutation of these variables, and we only find ourselves living in this particularly [fine-tuned](https://en.wikipedia.org/wiki/Fine-tuned_universe) universe due to a survival bias. These arbitrary variables collectively form another arbitrary object upon which an objective universe forms. It's almost coming from the other way - from the unknowable into the objective, whereas we are coming from the subjective to the objective.

Why is this important? Because it means that you *cannot* build a full set of philosophical systems using entirely reason, logic, empiricism and science. Any set of philosophical systems must contain an arbitrary object, which we call ethics. You can certainly create that arbitrary object with the assistance of some external authority like religion or popular opinion, but I think that just kicks the arbitrary can down the road. It also means that you cannot arrive at a system of ethics through these objective means. Your preference between potential futures is fundamentally irrational.